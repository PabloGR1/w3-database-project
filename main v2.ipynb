{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6d3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b364bc",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d9e57c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\pable\\anaconda3\\lib\\site-packages (8.0.29)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in c:\\users\\pable\\anaconda3\\lib\\site-packages (from mysql-connector-python) (3.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807c4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "801c287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear conexion a sql\n",
    "\n",
    "conexion = conn.connect(host='localhost', user='root', passwd='1a2a3a4a') # conexion al servidor\n",
    "\n",
    "cursor=conexion.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a19d30c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('blockbuster',)\n",
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sakila',)\n",
      "('sys',)\n",
      "('world',)\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "cursor.execute('show databases;')\n",
    "\n",
    "for x in cursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce3ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conectamos a bbdd Bloackbuster\n",
    "db = conn.connect(host='localhost', user='root', passwd='1a2a3a4a', database='blockbuster')\n",
    "\n",
    "cursor=db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5e0fc",
   "metadata": {},
   "source": [
    "## SQL Archemi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12f2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\pable\\anaconda3\\lib\\site-packages (1.4.32)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pable\\anaconda3\\lib\\site-packages (from SQLAlchemy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pymysql in c:\\users\\pable\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install SQLAlchemy\n",
    "%pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3c07b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "str_conn='mysql+pymysql://root:1a2a3a4a@localhost:3306'\n",
    "\n",
    "cursor=create_engine(str_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4d802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_conn='mysql+pymysql://root:1a2a3a4a@localhost:3306/blockbuster'\n",
    "\n",
    "cursor=create_engine(str_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca15eed",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d2564",
   "metadata": {},
   "source": [
    "# Inicio proceso de importación y limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4003759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista con todos los ficheros que queremos importar\n",
    "nom_ficheros = [\"actor\", \"category\", \"inventory\", \"language\", \"old_HDD\", \"rental\", \"film\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "410ce990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para cargar ficheros asignandolo a la variable \"data_[Nombre del fichero]\"\n",
    "# Ruta = Ruta del pc donde tienes los csv a cargar\n",
    "# x = lista de ficheros a cargar\n",
    "\n",
    "def carga_ficheros (x):\n",
    "    \n",
    "    Ruta = '../w3-database-project/Ficheros originales/data/'\n",
    "    globals()[f\"data_{x}\"] = pd.read_csv(Ruta+ x +'.csv', encoding=\"latin1\")\n",
    "\n",
    "    return #globals()[f\"data_{x}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d7bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de las columnas que queremos limpiar ** ¡ ojo, se borran de todas las tablas ! **\n",
    "delete_columns = ['last_update', 'original_language_id', 'release_year' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e555211d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mdata_actor) \n",
      " El tamaño original de la tabla es : (200, 4)\u001b[0m\n",
      "\u001b[92m El tamaño de la tabla despues de limpiar es : (200, 3)\u001b[0m\n",
      "\u001b[95m------> Se han eliminado \u001b[1m0 filas, y 1 columna\u001b[0m\n",
      "\u001b[94mdata_category) \n",
      " El tamaño original de la tabla es : (16, 3)\u001b[0m\n",
      "\u001b[92m El tamaño de la tabla despues de limpiar es : (16, 2)\u001b[0m\n",
      "\u001b[95m------> Se han eliminado \u001b[1m0 filas, y 1 columna\u001b[0m\n",
      "\u001b[94mdata_inventory) \n",
      " El tamaño original de la tabla es : (1000, 4)\u001b[0m\n",
      "\u001b[92m El tamaño de la tabla despues de limpiar es : (1000, 3)\u001b[0m\n",
      "\u001b[95m------> Se han eliminado \u001b[1m0 filas, y 1 columna\u001b[0m\n",
      "\u001b[94mdata_language) \n",
      " El tamaño original de la tabla es : (6, 3)\u001b[0m\n",
      "\u001b[92m El tamaño de la tabla despues de limpiar es : (6, 2)\u001b[0m\n",
      "\u001b[95m------> Se han eliminado \u001b[1m0 filas, y 1 columna\u001b[0m\n",
      "\u001b[94mdata_old_HDD) \n",
      " El tamaño original de la tabla es : (1000, 5)\u001b[0m\n",
      "\u001b[92m El tamaño de la tabla despues de limpiar es : (1000, 4)\u001b[0m\n",
      "\u001b[95m------> Se han eliminado \u001b[1m0 filas, y 1 columna\u001b[0m\n",
      "\u001b[94mdata_rental) \n",
      " El tamaño original de la tabla es : (1000, 7)\u001b[0m\n",
      "\u001b[92m El tamaño de la tabla despues de limpiar es : (1000, 6)\u001b[0m\n",
      "\u001b[95m------> Se han eliminado \u001b[1m0 filas, y 1 columna\u001b[0m\n",
      "\u001b[94mdata_film) \n",
      " El tamaño original de la tabla es : (1000, 13)\u001b[0m\n",
      "\u001b[92m El tamaño de la tabla despues de limpiar es : (1000, 10)\u001b[0m\n",
      "\u001b[95m------> Se han eliminado \u001b[1m0 filas, y 3 columnas\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# bucle para limpiar tabla y compración de shapes\n",
    "\n",
    "lista_tablas = []\n",
    "\n",
    "for x in nom_ficheros:\n",
    "    \n",
    "    carga_ficheros (x) # llamamos a la funcion carga_ficheros\n",
    "    print('\\033[94m' f\"data_{x}) \\n El tamaño original de la tabla es : \" + str(globals()[f\"data_{x}\"].shape) + '\\033[0m') # mostramos tamañao tabla original\n",
    "    num_filas_original= int((globals()[f\"data_{x}\"].shape)[0])\n",
    "    num_columnas_original = int((globals()[f\"data_{x}\"].shape)[1])\n",
    "    \n",
    "    #empezamos limpieza (quitar duplicado y eliminar columnas definidas anteriormente)\n",
    "    globals()[f\"data_{x}\"].drop_duplicates()\n",
    "    \n",
    "    for d in delete_columns:\n",
    "        if d in globals()[f\"data_{x}\"].columns:\n",
    "            globals()[f\"data_{x}\"].drop(d, axis=1, inplace = True)\n",
    "    num_filas_limpias= int((globals()[f\"data_{x}\"].shape)[0])\n",
    "    num_columnas_limpias = int((globals()[f\"data_{x}\"].shape)[1])\n",
    "            \n",
    "    print('\\033[92m' f\" El tamaño de la tabla despues de limpiar es : \" + str(globals()[f\"data_{x}\"].shape)+ '\\033[0m') #mostramos tamaño final de las tablas\n",
    "    \n",
    "    rest_filas = (num_filas_original - num_filas_limpias)\n",
    "    rest_columnas = (num_columnas_original - num_columnas_limpias)\n",
    "        \n",
    "    if rest_filas == 0 and rest_columnas == 0 :\n",
    "        print('\\033[1m'f'------> No se han eliminado ninguna fila/columna ')\n",
    "    \n",
    "    elif rest_filas == 1 and rest_columnas == 0 :\n",
    "        print('\\033[95m' f'------> Se han eliminado ''\\033[1m' + str(rest_filas) + ' fila, y ' + str(rest_columnas) + ' columnas''\\033[0m')\n",
    "    \n",
    "    elif rest_filas == 0 and rest_columnas == 1 :\n",
    "        print('\\033[95m' f'------> Se han eliminado ''\\033[1m' + str(rest_filas) + ' filas, y ' + str(rest_columnas) + ' columna''\\033[0m')\n",
    "        \n",
    "    else:\n",
    "        print('\\033[95m' f'------> Se han eliminado ''\\033[1m' + str(rest_filas) + ' filas, y ' + str(rest_columnas) + ' columnas''\\033[0m')\n",
    "\n",
    "\n",
    "    lista_tablas.append(f\"data_{x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e9b239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_actor['Nombre_completo']=data_actor['first_name']+\" \"+data_actor['last_name']\n",
    "data_old_HDD['Nombre_completo']=data_old_HDD['first_name']+\" \"+data_old_HDD['last_name'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab7fe1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca97fe7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5442a",
   "metadata": {},
   "source": [
    "## Carga de ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e16f68d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 332 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for x in lista_tablas:\n",
    "    globals()[f\"{x}\"].to_sql(name=x, con=cursor, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
